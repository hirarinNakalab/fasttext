{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exec(open('./preProcess.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('./fileConcat.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./validation/data120.txt\n",
      "./validation/data103.txt\n",
      "./validation/data127.txt\n",
      "./validation/sample_G.txt\n",
      "./validation/data102.txt\n",
      "./validation/data113.txt\n",
      "./validation/data114.txt\n",
      "./validation/data097.txt\n",
      "./validation/data108.txt\n",
      "./validation/sample_K.txt\n",
      "./validation/data100.txt\n",
      "./validation/data126.txt\n",
      "./validation/sample_H.txt\n",
      "./validation/data104.txt\n",
      "./validation/data121.txt\n",
      "./validation/data123.txt\n",
      "./validation/data110.txt\n",
      "./validation/data129.txt\n",
      "./validation/data107.txt\n",
      "./validation/data101.txt\n",
      "./validation/data122.txt\n",
      "./validation/data106.txt\n",
      "./validation/data128.txt\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import fasttext as ft\n",
    "import subprocess as cmd\n",
    "\n",
    "INPUT_VALI_DIR = './validation/'\n",
    "ENC_CONFIG = 'utf-8'\n",
    "\n",
    "classifier = ft.load_model('negaposi.bin')\n",
    "\n",
    "def get_all_files(in_dir):\n",
    "    for root, dirs, files in os.walk(in_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "def read_document(path, encoding):\n",
    "    with open(path, 'r', encoding=encoding, errors='ignore') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def corpus_to_sentences(corpus, encoding):\n",
    "    docs = [read_document(x, encoding) for x in corpus]\n",
    "    for idx, (doc, name) in enumerate(zip(docs, corpus)):\n",
    "        yield split_into_words(doc, name)\n",
    "        \n",
    "def trim_doc(doc):\n",
    "    lines = doc.splitlines()\n",
    "    valid_lines = []\n",
    "    for line in lines:\n",
    "        line = re.sub(r'[＜＞]', ' ', line) #正規表現置換\n",
    "        line = re.sub(r'^F\\d\\d\\d：', '', line)\n",
    "        line = re.sub(r'Ｘ：', '', line)\n",
    "        line = re.sub(r'^M\\d\\d\\d：', '', line)\n",
    "        if line.startswith('＠'):\n",
    "            continue\n",
    "        if line == '':\n",
    "            continue\n",
    "        if line.startswith('％'):\n",
    "            continue\n",
    "        valid_lines.append(line) #別リストにする\n",
    "    return valid_lines\n",
    "\n",
    "def split_into_words(doc, name=''):\n",
    "    valid_doc = trim_doc(doc)\n",
    "    houhan_prob = 0\n",
    "    daily_prob = 0\n",
    "\n",
    "    print(name)\n",
    "    for document in valid_doc: \n",
    "        morp = cmd.getstatusoutput(\"echo \" + document + \" | mecab -Owakati -d /usr/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "        words = morp[1]\n",
    "        estimate = classifier.predict([words], k=2)\n",
    "        estimate_2 = classifier.predict_proba([words], k=2)\n",
    "        if estimate[0][0] == \"__label__1,\":\n",
    "            daily_prob += estimate_2[0][0][1]\n",
    "        elif estimate[0][0] == \"__label__2,\":\n",
    "            houhan_prob += estimate_2[0][0][1]\n",
    "    houhan_prob /= len(valid_doc)\n",
    "    daily_prob /= len(valid_doc)\n",
    "    return (name, houhan_prob, daily_prob)\n",
    "\n",
    "\n",
    "corpus = list(get_all_files(INPUT_VALI_DIR))\n",
    "sentences = list(corpus_to_sentences(corpus, ENC_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./validation/data120.txt', 0, 672.0527960000034)\n",
      "('./validation/data103.txt', 0.5625, 2464.5510110000573)\n",
      "('./validation/data127.txt', 0.841797, 908.6582960000105)\n",
      "('./validation/sample_G.txt', 7.664064000000001, 4.046874)\n",
      "('./validation/data102.txt', 0, 999.8653290000123)\n",
      "('./validation/data113.txt', 1.699219, 1567.213025000027)\n",
      "('./validation/data114.txt', 0, 794.7676500000052)\n",
      "('./validation/data097.txt', 0.529297, 1048.2071260000132)\n",
      "('./validation/data108.txt', 2.357422, 787.7637410000049)\n",
      "('./validation/sample_K.txt', 5.4238290000000005, 5.726561)\n",
      "('./validation/data100.txt', 0, 1164.8106570000175)\n",
      "('./validation/data126.txt', 0, 782.6348350000054)\n",
      "('./validation/sample_H.txt', 5.619139, 2.9394540000000005)\n",
      "('./validation/data104.txt', 0, 1378.5470080000246)\n",
      "('./validation/data121.txt', 0, 483.97856399999904)\n",
      "('./validation/data123.txt', 0, 1639.0001580000335)\n",
      "('./validation/data110.txt', 0, 709.6797530000039)\n",
      "('./validation/data129.txt', 0, 599.6348130000014)\n",
      "('./validation/data107.txt', 0, 914.7325020000096)\n",
      "('./validation/data101.txt', 0, 741.0547560000052)\n",
      "('./validation/data122.txt', 0, 673.214905000004)\n",
      "('./validation/data106.txt', 0, 754.0137490000045)\n",
      "('./validation/data128.txt', 0, 788.2344490000066)\n",
      "('./validation/data109.txt', 0, 794.1738990000063)\n",
      "('./validation/data091.txt', 0, 589.6621650000004)\n",
      "('./validation/sample_B.txt', 9.070312999999999, 3.427734)\n",
      "('./validation/data119.txt', 0, 1478.4630420000287)\n",
      "('./validation/sample_J.txt', 5.7148449999999995, 4.0859380000000005)\n",
      "('./validation/data094.txt', 0, 448.86917799999935)\n",
      "('./validation/sample_A.txt', 7.123047, 4.535157)\n",
      "('./validation/data098.txt', 0, 1034.8106420000136)\n",
      "('./validation/sample_C.txt', 4.623047, 8.333985)\n",
      "('./validation/data118.txt', 0, 1085.7090880000126)\n",
      "('./validation/data095.txt', 0.693359, 1083.5176750000135)\n",
      "('./validation/data125.txt', 0, 936.3399390000116)\n",
      "('./validation/data096.txt', 0.884766, 1325.1759020000209)\n",
      "('./validation/data105.txt', 0.833984, 908.2344540000107)\n",
      "('./validation/data099.txt', 0, 694.1934230000043)\n",
      "('./validation/data116.txt', 0, 1378.304824000025)\n",
      "('./validation/data093.txt', 1.208984, 677.6621730000035)\n",
      "('./validation/sample_L.txt', 7.703125, 1.7832029999999999)\n",
      "('./validation/sample_I.txt', 7.939452999999999, 2.4179690000000003)\n",
      "('./validation/data115.txt', 0, 578.7207550000008)\n",
      "('./validation/data124.txt', 0, 600.7481060000011)\n",
      "('./validation/data092.txt', 0.783203, 1484.338025000025)\n",
      "('./validation/data117.txt', 0, 1113.0958110000163)\n",
      "('./validation/data112.txt', 1.556641, 1445.890755000025)\n",
      "('./validation/data111.txt', 1.101563, 850.1094440000069)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences[i])\n",
    "    values.append(sentences[i][1])\n",
    "    if 'data'in sentences[i][0]:\n",
    "        label = 1\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        label = 2\n",
    "        labels.append(label)\n",
    "\n",
    "y = np.array(labels)        \n",
    "scores = np.array(values)\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plt.plot(fpr, tpr, label='cosine similarity of PV-DM (area = %.2f)' %auc)\n",
    "# plt.legend()\n",
    "# plt.title('Sales Visit - Receiver Operating Characteristic')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.grid(True)\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n",
    "# plt.savefig('roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
