{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exec(open('./preProcess.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('./fileConcat.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./validation/data120.txt\n",
      "./validation/data103.txt\n",
      "./validation/data127.txt\n",
      "./validation/sample_G.txt\n",
      "./validation/data102.txt\n",
      "./validation/data113.txt\n",
      "./validation/data114.txt\n",
      "./validation/data097.txt\n",
      "./validation/data108.txt\n",
      "./validation/sample_K.txt\n",
      "./validation/data100.txt\n",
      "./validation/data126.txt\n",
      "./validation/sample_H.txt\n",
      "./validation/data104.txt\n",
      "./validation/data121.txt\n",
      "./validation/data123.txt\n",
      "./validation/data110.txt\n",
      "./validation/data129.txt\n",
      "./validation/data107.txt\n",
      "./validation/data101.txt\n",
      "./validation/data122.txt\n",
      "./validation/data106.txt\n",
      "./validation/data128.txt\n",
      "./validation/data109.txt\n",
      "./validation/data091.txt\n",
      "./validation/sample_B.txt\n",
      "./validation/data119.txt\n",
      "./validation/sample_J.txt\n",
      "./validation/data094.txt\n",
      "./validation/sample_A.txt\n",
      "./validation/data098.txt\n",
      "./validation/sample_C.txt\n",
      "./validation/data118.txt\n",
      "./validation/data095.txt\n",
      "./validation/data125.txt\n",
      "./validation/data096.txt\n",
      "./validation/data105.txt\n",
      "./validation/data099.txt\n",
      "./validation/data116.txt\n",
      "./validation/data093.txt\n",
      "./validation/sample_L.txt\n",
      "./validation/sample_I.txt\n",
      "./validation/data115.txt\n",
      "./validation/data124.txt\n",
      "./validation/data092.txt\n",
      "./validation/data117.txt\n",
      "./validation/data112.txt\n",
      "./validation/data111.txt\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import fasttext as ft\n",
    "import subprocess as cmd\n",
    "\n",
    "INPUT_VALI_DIR = './validation/'\n",
    "ENC_CONFIG = 'utf-8'\n",
    "\n",
    "classifier = ft.load_model('negaposi.bin')\n",
    "\n",
    "def get_all_files(in_dir):\n",
    "    for root, dirs, files in os.walk(in_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "def read_document(path, encoding):\n",
    "    with open(path, 'r', encoding=encoding, errors='ignore') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def corpus_to_sentences(corpus, encoding):\n",
    "    docs = [read_document(x, encoding) for x in corpus]\n",
    "    for idx, (doc, name) in enumerate(zip(docs, corpus)):\n",
    "        yield split_into_words(doc, name)\n",
    "        \n",
    "def trim_doc(doc):\n",
    "    lines = doc.splitlines()\n",
    "    valid_lines = []\n",
    "    for line in lines:\n",
    "        line = re.sub(r'[＜＞]', ' ', line) #正規表現置換\n",
    "        line = re.sub(r'^F\\d\\d\\d：', '', line)\n",
    "        line = re.sub(r'Ｘ：', '', line)\n",
    "        line = re.sub(r'^M\\d\\d\\d：', '', line)\n",
    "        if line.startswith('＠'):\n",
    "            continue\n",
    "        if line == '':\n",
    "            continue\n",
    "        if line.startswith('％'):\n",
    "            continue\n",
    "        valid_lines.append(line) #別リストにする\n",
    "    return valid_lines\n",
    "\n",
    "def split_into_words(doc, name=''):\n",
    "    valid_doc = trim_doc(doc)\n",
    "    houhan_prob = 0\n",
    "    daily_prob = 0\n",
    "\n",
    "    print(name)\n",
    "    for document in valid_doc: \n",
    "        morp = cmd.getstatusoutput(\"echo \" + document + \" | mecab -Owakati -d /usr/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "        words = morp[1]\n",
    "        estimate = classifier.predict([words], k=2)\n",
    "        estimate_2 = classifier.predict_proba([words], k=2)\n",
    "        if estimate[0][0] == \"__label__1,\":\n",
    "            daily_prob += estimate_2[0][0][1]\n",
    "        elif estimate[0][0] == \"__label__2,\":\n",
    "            houhan_prob += estimate_2[0][0][1]\n",
    "#     houhan_prob /= len(valid_doc)\n",
    "#     daily_prob /= len(valid_doc)\n",
    "    return (name, houhan_prob, daily_prob)\n",
    "\n",
    "\n",
    "corpus = list(get_all_files(INPUT_VALI_DIR))\n",
    "sentences = list(corpus_to_sentences(corpus, ENC_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.91992200e+00  5.64257900e+00  5.52148400e+00  3.61719000e+00\n",
      "  2.67968500e+00  2.58789000e+00  1.62890700e+00 -3.02732000e-01\n",
      " -3.71093800e+00 -4.48869178e+02 -4.83978564e+02 -5.78720755e+02\n",
      " -5.89662165e+02 -5.99634813e+02 -6.00748106e+02 -6.72052796e+02\n",
      " -6.73214905e+02 -6.76453189e+02 -6.94193423e+02 -7.09679753e+02\n",
      " -7.41054756e+02 -7.54013749e+02 -7.82634835e+02 -7.85406319e+02\n",
      " -7.88234449e+02 -7.94173899e+02 -7.94767650e+02 -8.49007881e+02\n",
      " -9.07400470e+02 -9.07816499e+02 -9.14732502e+02 -9.36339939e+02\n",
      " -9.99865329e+02 -1.03481064e+03 -1.04767783e+03 -1.08282432e+03\n",
      " -1.08570909e+03 -1.11309581e+03 -1.16481066e+03 -1.32429114e+03\n",
      " -1.37830482e+03 -1.37854701e+03 -1.44433411e+03 -1.47846304e+03\n",
      " -1.48355482e+03 -1.56551381e+03 -1.63900016e+03 -2.46398851e+03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import csv\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for i in range(len(sentences)):\n",
    "    \n",
    "    values.append(sentences[i][1] - sentences[i][2])\n",
    "    if 'data'in sentences[i][0]:\n",
    "        label = 1\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        label = 2\n",
    "        labels.append(label)\n",
    "\n",
    "y = np.array(labels)        \n",
    "scores = np.array(values)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2, drop_intermediate=False)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(thresholds)\n",
    "\n",
    "plt.plot(fpr, tpr, label='fastText (area = %.2f)' %auc)\n",
    "plt.legend()\n",
    "plt.title('Sales Visit - Receiver Operating Characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n",
    "plt.savefig('roc.png')\n",
    "\n",
    "with open('./out.csv', \"w\") as wf:\n",
    "    writer = csv.writer(wf)\n",
    "    for i in range(len(y)):\n",
    "        writer.writerow([y[i], scores[i]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
